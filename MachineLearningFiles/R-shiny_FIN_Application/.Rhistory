rpart_pred <- predict(rpart_model, testset, type='class')
#myACCU <<- mean(rpart_pred == actual)
data.frame(actual, rpart_pred)
print(rpart_model)
rpart_confusion_matrix = table(rpart_pred, actual)
rpart_confusion_matrix
rpart_accuracy = sum(rpart_confusion_matrix[1,1]+rpart_confusion_matrix[2,2])/L
rpart_accuracy
#confusion_matrix <- confusionMatrix(rpart_pred, as.factor(actual))
#print(confusion_matrix)
rpart_accu_vect[j] = rpart_accuracy
nb_model <- naiveBayes(as.factor(target) ~ ., data = trainset)
nb_pred = predict(nb_model, testset)
myactualVpred <<- data.frame(actual, nb_pred)
print(nb_model)
nb_confusion_matrix = table(nb_pred, actual)
nb_confusion_matrix
nb_accuracy = sum(nb_confusion_matrix[1,1]+nb_confusion_matrix[2,2])/L
nb_accuracy
nb_accu_vect[j] = nb_accuracy
}
glm_df[i,2] <- mean(glm_accu_vect)
rpart_df[i,2] <- mean(rpart_accu_vect)
nb_df[i,2] <- mean(nb_accu_vect)
}
glm_df
rpart_df
nb_df
dataset <- read_csv("~/Documents/FIN_Application/data/mydata5.csv")
#dataset <- clean_names(dataset)
na.omit(dataset)
dataset$target <- revalue(dataset$target, c("Yes"= 1))
dataset$target <- revalue(dataset$target, c("No"= 0))
dataset$target <- as.factor(dataset$target)
dataset$category <- as.factor(dataset$category)
dataset$needorwant <- as.factor(dataset$needorwant)
dataset$desire <- as.factor(dataset$desire)
ratio <- c(.7,.8,.9)
mc <- 10
glm_df <- data.frame()
rpart_df <- data.frame()
nb_df <- data.frame()
for(i in 1:length(ratio)) {
glm_df[i,1] <- ratio[i]
rpart_df[i,1] <- ratio[i]
nb_df[i,1] <- ratio[i]
glm_accu_vect = c()
rpart_accu_vect = c()
nb_accu_vect = c()
for(j in 1:mc) {
n=nrow(dataset)
#set.seed(175)
indexes = sample(n,n*(ratio[i]))
trainset = dataset[indexes,]
testset = dataset[-indexes,]
actual <- testset$target
glm_model <- glm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
glm_accu_vect[j] = glm_accuracy
rpart_model <- rpart(target~., method="class", data=trainset)
rpart_pred <- predict(rpart_model, testset, type='class')
#myACCU <<- mean(rpart_pred == actual)
data.frame(actual, rpart_pred)
print(rpart_model)
rpart_confusion_matrix = table(rpart_pred, actual)
rpart_confusion_matrix
rpart_accuracy = sum(rpart_confusion_matrix[1,1]+rpart_confusion_matrix[2,2])/L
rpart_accuracy
#confusion_matrix <- confusionMatrix(rpart_pred, as.factor(actual))
#print(confusion_matrix)
rpart_accu_vect[j] = rpart_accuracy
nb_model <- naiveBayes(as.factor(target) ~ ., data = trainset)
nb_pred = predict(nb_model, testset)
myactualVpred <<- data.frame(actual, nb_pred)
print(nb_model)
nb_confusion_matrix = table(nb_pred, actual)
nb_confusion_matrix
nb_accuracy = sum(nb_confusion_matrix[1,1]+nb_confusion_matrix[2,2])/L
nb_accuracy
nb_accu_vect[j] = nb_accuracy
}
glm_df[i,2] <- mean(glm_accu_vect)
rpart_df[i,2] <- mean(rpart_accu_vect)
nb_df[i,2] <- mean(nb_accu_vect)
}
glm_df
rpart_df
nb_df
n=nrow(dataset)
#set.seed(175)
indexes = sample(n,n*(.7))
trainset = dataset[indexes,]
testset = dataset[-indexes,]
actual <- testset$target
n=nrow(dataset)
#set.seed(175)
indexes = sample(n,n*(.7))
trainset = dataset[indexes,]
testset = dataset[-indexes,]
actual <- testset$target
glm_model <- glm(target~ .,trainset,family = binomial)
ratio <- c(.7,.8,.9)
mc <- 10
glm_df <- data.frame()
rpart_df <- data.frame()
nb_df <- data.frame()
for(i in 1:length(ratio)) {
glm_df[i,1] <- ratio[i]
rpart_df[i,1] <- ratio[i]
nb_df[i,1] <- ratio[i]
glm_accu_vect = c()
rpart_accu_vect = c()
nb_accu_vect = c()
for(j in 1:mc) {
n=nrow(dataset)
#set.seed(175)
indexes = sample(n,n*(ratio[i]))
trainset = dataset[indexes,]
testset = dataset[-indexes,]
actual <- testset$target
glm_model <- brglm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
glm_accu_vect[j] = glm_accuracy
rpart_model <- rpart(target~., method="class", data=trainset)
rpart_pred <- predict(rpart_model, testset, type='class')
#myACCU <<- mean(rpart_pred == actual)
data.frame(actual, rpart_pred)
print(rpart_model)
rpart_confusion_matrix = table(rpart_pred, actual)
rpart_confusion_matrix
rpart_accuracy = sum(rpart_confusion_matrix[1,1]+rpart_confusion_matrix[2,2])/L
rpart_accuracy
#confusion_matrix <- confusionMatrix(rpart_pred, as.factor(actual))
#print(confusion_matrix)
rpart_accu_vect[j] = rpart_accuracy
nb_model <- naiveBayes(as.factor(target) ~ ., data = trainset)
nb_pred = predict(nb_model, testset)
myactualVpred <<- data.frame(actual, nb_pred)
print(nb_model)
nb_confusion_matrix = table(nb_pred, actual)
nb_confusion_matrix
nb_accuracy = sum(nb_confusion_matrix[1,1]+nb_confusion_matrix[2,2])/L
nb_accuracy
nb_accu_vect[j] = nb_accuracy
}
glm_df[i,2] <- mean(glm_accu_vect)
rpart_df[i,2] <- mean(rpart_accu_vect)
nb_df[i,2] <- mean(nb_accu_vect)
}
glm_df
rpart_df
nb_df
n=nrow(dataset)
#set.seed(175)
indexes = sample(n,n*(.7))
trainset = dataset[indexes,]
testset = dataset[-indexes,]
actual <- testset$target
glm_model <- brglm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
rpart_model <- rpart(target~., method="class", data=trainset)
rpart_pred <- predict(rpart_model, testset, type='class')
#myACCU <<- mean(rpart_pred == actual)
data.frame(actual, rpart_pred)
print(rpart_model)
rpart_confusion_matrix = table(rpart_pred, actual)
rpart_confusion_matrix
rpart_accuracy = sum(rpart_confusion_matrix[1,1]+rpart_confusion_matrix[2,2])/L
rpart_accuracy
nb_model <- naiveBayes(as.factor(target) ~ ., data = trainset)
nb_pred = predict(nb_model, testset)
myactualVpred <<- data.frame(actual, nb_pred)
print(nb_model)
nb_confusion_matrix = table(nb_pred, actual)
nb_confusion_matrix
nb_accuracy = sum(nb_confusion_matrix[1,1]+nb_confusion_matrix[2,2])/L
nb_accuracy
library(pmml)
rpart_pmml <- pmml(rpart_model, data=trainset)
nb_pmml <- pmml(nb_model, predictedField="target")
glm_df
rpart_df
nb_df
plot(glm_df)
plot(rpart_df)
plot(nb_df)
n=nrow(dataset)
#set.seed(175)
indexes = sample(n,n*(.7))
trainset = dataset[indexes,]
testset = dataset[-indexes,]
actual <- testset$target
glm_model <- brglm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
rpart_model <- rpart(target~., method="class", data=trainset)
rpart_pred <- predict(rpart_model, testset, type='class')
#myACCU <<- mean(rpart_pred == actual)
data.frame(actual, rpart_pred)
print(rpart_model)
rpart_confusion_matrix = table(rpart_pred, actual)
rpart_confusion_matrix
rpart_accuracy = sum(rpart_confusion_matrix[1,1]+rpart_confusion_matrix[2,2])/L
rpart_accuracy
nb_model <- naiveBayes(as.factor(target) ~ ., data = trainset)
nb_pred = predict(nb_model, testset)
myactualVpred <<- data.frame(actual, nb_pred)
print(nb_model)
nb_confusion_matrix = table(nb_pred, actual)
nb_confusion_matrix
nb_accuracy = sum(nb_confusion_matrix[1,1]+nb_confusion_matrix[2,2])/L
nb_accuracy
library(pmml)
rpart_pmml <- pmml(rpart_model, data=trainset)
nb_pmml <- pmml(nb_model, predictedField="target")
glm_pmml <- pmml(glm_model, name="glm_model", data=trainset)
dataset <- read_csv("~/Documents/FIN_Application/data/mydata5.csv")
#dataset <- clean_names(dataset)
na.omit(dataset)
dataset$target <- revalue(dataset$target, c("Yes"= 1))
dataset$target <- revalue(dataset$target, c("No"= 0))
dataset$target <- as.factor(dataset$target)
dataset$category <- as.factor(dataset$category)
dataset$needorwant <- as.factor(dataset$needorwant)
dataset$desire <- as.factor(dataset$desire)
ratio <- c(.7,.8,.9)
mc <- 10
glm_df <- data.frame()
rpart_df <- data.frame()
nb_df <- data.frame()
for(i in 1:length(ratio)) {
glm_df[i,1] <- ratio[i]
rpart_df[i,1] <- ratio[i]
nb_df[i,1] <- ratio[i]
glm_accu_vect = c()
rpart_accu_vect = c()
nb_accu_vect = c()
for(j in 1:mc) {
n=nrow(dataset)
#set.seed(175)
indexes = sample(n,n*(ratio[i]))
trainset = dataset[indexes,]
testset = dataset[-indexes,]
actual <- testset$target
glm_model <- brglm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
glm_accu_vect[j] = glm_accuracy
rpart_model <- rpart(target~., method="class", data=trainset)
rpart_pred <- predict(rpart_model, testset, type='class')
#myACCU <<- mean(rpart_pred == actual)
data.frame(actual, rpart_pred)
print(rpart_model)
rpart_confusion_matrix = table(rpart_pred, actual)
rpart_confusion_matrix
rpart_accuracy = sum(rpart_confusion_matrix[1,1]+rpart_confusion_matrix[2,2])/L
rpart_accuracy
#confusion_matrix <- confusionMatrix(rpart_pred, as.factor(actual))
#print(confusion_matrix)
rpart_accu_vect[j] = rpart_accuracy
nb_model <- naiveBayes(as.factor(target) ~ ., data = trainset)
nb_pred = predict(nb_model, testset)
myactualVpred <<- data.frame(actual, nb_pred)
print(nb_model)
nb_confusion_matrix = table(nb_pred, actual)
nb_confusion_matrix
nb_accuracy = sum(nb_confusion_matrix[1,1]+nb_confusion_matrix[2,2])/L
nb_accuracy
nb_accu_vect[j] = nb_accuracy
}
glm_df[i,2] <- mean(glm_accu_vect)
rpart_df[i,2] <- mean(rpart_accu_vect)
nb_df[i,2] <- mean(nb_accu_vect)
}
glm_df
rpart_df
nb_df
plot(glm_df)
plot(rpart_df)
plot(nb_df)
n=nrow(dataset)
#set.seed(175)
indexes = sample(n,n*(.7))
trainset = dataset[indexes,]
testset = dataset[-indexes,]
actual <- testset$target
glm_model <- brglm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
rpart_model <- rpart(target~., method="class", data=trainset)
rpart_pred <- predict(rpart_model, testset, type='class')
#myACCU <<- mean(rpart_pred == actual)
data.frame(actual, rpart_pred)
print(rpart_model)
rpart_confusion_matrix = table(rpart_pred, actual)
rpart_confusion_matrix
rpart_accuracy = sum(rpart_confusion_matrix[1,1]+rpart_confusion_matrix[2,2])/L
rpart_accuracy
nb_model <- naiveBayes(as.factor(target) ~ ., data = trainset)
nb_pred = predict(nb_model, testset)
myactualVpred <<- data.frame(actual, nb_pred)
print(nb_model)
nb_confusion_matrix = table(nb_pred, actual)
nb_confusion_matrix
nb_accuracy = sum(nb_confusion_matrix[1,1]+nb_confusion_matrix[2,2])/L
nb_accuracy
library(pmml)
rpart_pmml <- pmml(rpart_model, data=trainset)
nb_pmml <- pmml(nb_model, predictedField="target")
glm_pmml <- pmml(glm_model, name="glm_model", data=trainset)
write(toString((rpart_pmml), file="rpart.pmml"))
glm_pmml <- pmml(glm_model)
glm_pmml <- pmml(glm_model, name="glm model", data=trainset)
glm_pmml <- pmml(glm_model)
glm_model
nb_pmml <- pmml(nb_model, predictedField="target")
glm_pmml <- pmml(glm_model, name="glm model", data=trainset)
rpart_pmml <- pmml(rpart_model, data=trainset)
nb_pmml <- pmml(nb_model, predictedField="target")
glm_pmml <- pmml(glm_model, name="glm model", data=trainset)
glm_pmml <- pmml.glm(glm_model, name="glm model", data=trainset)
glm_model
glm_pmml <- pmml.glm(glm_model, name="glm model")
glm_model <- brglm(target~ .,trainset)
glm_model <- brglm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
glm_model <- glm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
rpart_model <- rpart(target~., method="class", data=trainset)
rpart_pred <- predict(rpart_model, testset, type='class')
#myACCU <<- mean(rpart_pred == actual)
data.frame(actual, rpart_pred)
print(rpart_model)
rpart_confusion_matrix = table(rpart_pred, actual)
rpart_confusion_matrix
rpart_accuracy = sum(rpart_confusion_matrix[1,1]+rpart_confusion_matrix[2,2])/L
rpart_accuracy
nb_model <- naiveBayes(as.factor(target) ~ ., data = trainset)
nb_pred = predict(nb_model, testset)
myactualVpred <<- data.frame(actual, nb_pred)
print(nb_model)
nb_confusion_matrix = table(nb_pred, actual)
nb_confusion_matrix
nb_accuracy = sum(nb_confusion_matrix[1,1]+nb_confusion_matrix[2,2])/L
nb_accuracy
library(pmml)
rpart_pmml <- pmml(rpart_model, data=trainset)
nb_pmml <- pmml(nb_model, predictedField="target")
glm_pmml <- pmml.glm(glm_model, name="glm model", data=trainset)
write(toString((rpart_pmml), file="rpart.pmml"))
write(toString((nb_pmml), file="nb.pmml"))
write(toString((glm_pmml), file="glm.pmml"))
saveXML(rpart_pmml,file="rpart.pmml")
saveXML(nb_pmml,file="nb.pmml")
saveXML(glm_pmml,file="glm.pmml")
levels(dataset$target)
levels(dataset$category)
glm_model <- brglm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
glm_model <- glm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
glm_model <- glm(target~ .,trainset,family = binomial)
summary(glm_model)
glm_pred=predict(glm_model, testset, type="response") # fit testset against the model. predict value of y in the testset
L=length(glm_pred)
glm_predictedvalues=rep(0,L) #repeat zeros L times.... declare a vector of zeros
glm_predictedvalues[glm_pred>0.5]=1 #take each cell in phat_i and if it's greather than .5 it's 1.
data.frame(actual,glm_predictedvalues)
glm_confusion_matrix = table(glm_predictedvalues, actual)
glm_confusion_matrix
glm_accuracy = sum(glm_confusion_matrix[1,1]+glm_confusion_matrix[2,2])/L
glm_accuracy
library(readr)
donedealcars2 <- read_csv("Downloads/donedealcars2.csv")
head(donedealcars2)
x1=data$Mileage
x1=data$Mileage
y=data$PRICE
dataset<-na.omit(data.frame(x1,y))
dim(dataset)
head(donedealcars2)
donedealcars2 <- read_csv("Downloads/donedealcars2.csv")
head(donedealcars2)
x1=data$Mileage
x1=data$"NEW MILEAGE"
y=data$PRICE
dataset<-na.omit(data.frame(x1,y))
dim(dataset)
x1
x1=data$"NEW MILEAGE"
y=data$PRICE
dataset<-na.omit(data.frame(x1,y))
dim(dataset)
dataset <- clean_names(dataset)
dataset
library(readr)
data <- read_csv("Downloads/donedealcars2.csv")
library(readr)
data <- read_csv("Downloads/donedealcars2.csv")
head(data)
dataset<-na.omit(data.frame(x1,y))
View(dataset)
library(readr)
data <- read_csv("Downloads/donedealcars2.csv")
head(data)
dataset <- clean_names(data)
dataset
dataset <- clean_names(data)
dataset
library(readr)
data <- read_csv("Downloads/donedealcars2.csv")
head(data)
dataset <- clean_names(data)
x1=dataset$new_mileage
y=dataset$price
dataset<-na.omit(data.frame(x1,y))
dim(dataset)
library(readr)
data <- read_csv("Downloads/donedealcars2.csv")
head(data)
dataset <- clean_names(data)
x1=dataset$new_mileage
y=dataset$price
dataset<-na.omit(data.frame(x1,y))
dim(dataset)
fit=lm(y~., data=dataset)
summary(fit)
data <- read_csv("Downloads/donedealcars2.csv")
head(data)
dataset <- clean_names(data)
fit=lm(price~., data=dataset)
shiny::runApp('Documents/2MLRMACHINELEARNINGAPP')
runApp('~/Desktop/B8RS100_MARYLOUISEREYES/MachineLearningFiles/R-shiny_FIN_Application')
